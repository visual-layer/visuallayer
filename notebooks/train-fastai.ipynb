{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using `vl_datasets` with fast.ai\n",
    "This Jupyter notebook shows how to load clean datasets from `vl-dataset` into [fastai](https://github.com/fastai/fastai) for training a model. \n",
    "\n",
    "<!--<badge>--><a href=\"https://colab.research.google.com/github/visual-layer/vl-datasets/blob/master/notebooks/train-fastai.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a><!--</badge>-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation & Setting Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install vl-datasets fastai timm -Uqq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the preprocessing transforms\n",
    "We define the preprocessing transforms for the dataset. We have two transforms: `train_transform` and `valid_transform`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "\n",
    "train_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "valid_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download and load the food-101 Dataset\n",
    "\n",
    "The easiest way to get the clean version of food-101 dataset is to use `vl_dataset` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excluded 407 from the train set\n",
      "Excluded 91 from the test set\n"
     ]
    }
   ],
   "source": [
    "from vl_datasets import CleanFood101\n",
    "\n",
    "train_dataset = CleanFood101('./', split='train', exclude_csv='csv_files/food_101_vl-datasets_analysis.csv', transform=train_transform)\n",
    "valid_dataset = CleanFood101('./', split='test', exclude_csv='csv_files/food_101_vl-datasets_analysis.csv', transform=valid_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upon completion, you'd have with a `food-101` folder in your local directory.\n",
    "\n",
    "```\n",
    "food-101/\n",
    "├── images\n",
    "│   ├── apple_pie\n",
    "│   │   ├── 0001.jpg\n",
    "│   │   └── 0002.jpg\n",
    "│   ├── baby_back_ribs\n",
    "│   ├── baklava\n",
    "│   ├── ...\n",
    "│   ├── ...\n",
    "│   ├── ...\n",
    "│   └── waffles\n",
    "├── meta\n",
    "|   ├── classes.txt\n",
    "│   ├── labels.txt\n",
    "│   ├── test.json\n",
    "│   ├── test.txt\n",
    "│   ├── train.json\n",
    "│   └── train.txt\n",
    "├── license_agreement.txt\n",
    "└── README.txt\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you'd like to download the food-101 manually, you run the following codes to download and extract the folder into your local directory.\n",
    "\n",
    "```shell\n",
    "wget http://data.vision.ee.ethz.ch/cvl/food-101.tar.gz\n",
    "tar -xf food-101.tar.gz\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, load the directory into a `CleanFood101` class.\n",
    "\n",
    "```python\n",
    "train_dataset = CleanFood101('./', download=False, split='train', exclude_csv='food_101_vl-datasets_analysis.csv', transform=train_transform)\n",
    "valid_dataset = CleanFood101('./', download=False, split='test', exclude_csv='food_101_vl-datasets_analysis.csv', transform=train_transform)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View the list of excluded files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_dataset.excluded_files[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=256, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert PyTorch `Dataloader` to fastai `Dataloader` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.data.core import DataLoaders\n",
    "dls = DataLoaders(train_loader, valid_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries\n",
    "\n",
    "The `fastai.vision.all` module contains all the classes and functions for computer vision tasks in the fastai library, while the timm library provides a collection of state-of-the-art CNN architectures for image classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define and Train the Model\n",
    "\n",
    "The next step is to define and train the CNN model using the Fastai library. The following code defines a vision learner with the convnext_tiny_in22k architecture from the timm library and the accuracy metric.\n",
    "\n",
    "The vision_learner function creates a CNN model with the specified architecture and data, and the metrics argument specifies the evaluation metric to use during training. In this case, the accuracy metric is used to measure the percentage of correctly classified images. The to_fp16 method is used to convert the model to half-precision floating-point format, which reduces memory usage and speeds up training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can optionally use model from `timm` in fastai. For example:\n",
    "\n",
    "```python\n",
    "import timm\n",
    "model = timm.create_model(\"hf-hub:timm/eca_nfnet_l0\", pretrained=True)\n",
    "learn = Learner(dls, model, loss_func=LabelSmoothingCrossEntropy(), metrics=accuracy, opt_func=ranger).to_fp16()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(dls, resnet18(), loss_func=LabelSmoothingCrossEntropy(), metrics=accuracy).to_fp16()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to find the optimal learning rate for training the model using the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function finds the learning rate that results in the steepest decrease in the loss function during training, which is a good starting point for fine-tuning the model.\n",
    "\n",
    "Finally, the following code is used to fine-tune the model on the dataset for 5 epochs with a learning rate of 1e-3 and a ShowGraphCallback to plot the training and validation loss over time:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "learn.fine_tune(5, base_lr=5e-3, cbs=[ShowGraphCallback()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fine_tune method is used to fine-tune the model on the dataset for the specified number of epochs, and the base_lr argument specifies the learning rate to use for the final layers of the model. The ShowGraphCallback is a custom callback that plots the training and validation loss over time.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Results\n",
    "Once of the ways to learn about the performance of your model is to evaluate it on the validation set. For classification tasks it's easy to use confusion matrix to gauge the model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn.get_preds(dls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# interp = ClassificationInterpretation.from_learner(learn)\n",
    "# interp.plot_confusion_matrix(figsize=(5,5), dpi=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export the Trained Model\n",
    "\n",
    "The export method is used to save the model to a file with the specified path and name. This trained model can be loaded later for inference or further fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "learn = learn.to_fp32()\n",
    "learn.save('myModel', with_opt=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it! This notebook shows how to train a CNN model using the Fastai library with a pretrained architecture from the timm library. By following the steps in this notebook, you can easily train your own CNN models on image datasets using fastai.\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
